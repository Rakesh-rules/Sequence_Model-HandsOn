{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f3c3ad",
   "metadata": {},
   "source": [
    "# Sequence Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b17fc8",
   "metadata": {},
   "source": [
    "- Like speech recognition to text, Music generation, text prediction, sentiment analysis, DNA sequence analysis, Machine translation(language translation), video activity recognition and name entity recognition (find names from sentence), etc.\n",
    "\n",
    "\n",
    "## Representing Words\n",
    "\n",
    "- A vocabulary is used, consisting of Common words used in language.The size of this vocabulary can vary based on the projects or company.\n",
    "- This vocabulary is represented as a **one hot vector**, Which is Array of Zeros and only the index of the word will get the value one.\n",
    "- The words, which are not available in the vocabulary Are marked with <unk>\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*YFh3GZ41PgQWAnB_LfmJVw.png)\n",
    "\n",
    "## Simplified RNN notation\n",
    "\n",
    "- When the neural network reads the sentence, It feeds on the first word _X<sup><1></sup>_ and outputs the result _Y<sup><1></sup>_. At next timestamp it reads on the next word and proceeds.\n",
    "\n",
    "    ![](http://persagen.com/files/misc/unfolded-RNN.png)\n",
    "\n",
    "- **tanh** or **Relu** is used for activation function on _h<sub>t</sub>_. tanh is a common choice. Activation function for _Y<sub>`<t>`</sub>_ is based on its problem kind, for example sigmoid is used for binary classification.\n",
    "\n",
    "    ![](https://www.yuthon.com/images/RNN_concept.png)\n",
    "\n",
    "\n",
    "### Forward Propagation\n",
    "\n",
    "- _f<sub>w</sub>_ is formed by stacking _W<sub>hh</sub>_ and _W<sub>xh</sub>_ side by side forming a matrix.\n",
    "\n",
    "- _b<sub>y</sub>_ is a bias value added to this equation.\n",
    "\n",
    "    ![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi.stack.imgur.com%2FEtV8U.png&f=1&nofb=1)\n",
    "\n",
    "### Back Propagation through time\n",
    "\n",
    "- Mostly DL frameworks takes care of backpropagation.\n",
    "\n",
    "- The loss function is defined as the logistic regression loss (cross-entropy loss) for each time step, the total loss would be a summation of them.\n",
    "\n",
    "- The backpropagation is done similarly like standard networks but done for each time stamp allowing to update parameters along each word. As this backpropagation along the timestamp is significant is known as backpropagation through time.\n",
    "\n",
    "    ![](https://raw.githubusercontent.com/mmuratarat/mmuratarat.github.io/master/_posts/images/BPTT.png)\n",
    "\n",
    "## Types of RNN\n",
    "\n",
    "1. One-to-Many\n",
    "\n",
    "   - Pass single value and the network provides a series of outputs\n",
    "   - Eg. Music Generation\n",
    "\n",
    "1. Many-to-Many\n",
    "\n",
    "   - Input and output length may or may not be exactly same.\n",
    "   - Eg. Machine translation - Translation from one language which has different lengths for input and output.\n",
    "   - Here, The input is handled by a encoder that gets the input from one language with many words and the output will be provided by a decoder with many words of same or different length.\n",
    "\n",
    "1. One-to-One\n",
    "   - Need not be RNN, might be a simple Neural network.\n",
    "\n",
    "1. Many-to-One\n",
    "   - Takes all(many) input and provides one output at the end. \n",
    "   - Eg. Sentiment analysis, text classification.\n",
    "\n",
    "    ![](https://static.javatpoint.com/tutorial/tensorflow/images/tensorflow-types-of-rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e8004",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c7a3a",
   "metadata": {},
   "source": [
    "- To build such a model in RNN, we need a training set of\n",
    "  large corpus of english text. **_Corpus_** is a NLP terminology that means a very large set or body of text or sentences.\n",
    "- First we need to tokenize the sentences and form a **_vocabulary_** of known words.\n",
    "- While modelling, common thing is to add one more token `<eos>` to _represent the **end of the sentence**_. we can also decide whether to tokenize _punctuations_.\n",
    "- Another details is that we can use `<unk>` or any unique token for _**unknown words** that are not present in vocabulary_. Say we have 10,000 most used words in english as vocabulary, we can use `<unk>` for other words.\n",
    "\n",
    "![](https://miro.medium.com/max/1134/1*lhH8dFbK5_saNe4kcWXwiA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099fb669",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80fe44",
   "metadata": {},
   "source": [
    "- We might end up setting input $x^{<t>} = y^{<t-1>}$. i.e, _the output of previous timestamp as the next input_.\n",
    "- $\\hat{y}^{<t>}$ is a 10000 way **_softmax output_**, if you have a 10000 word vocabulary.\n",
    "- Each step of _RNN will look at some set of preceding words_. So, the RNN learns to predict one word at a time going from left to right.\n",
    "- Next to train this Network, we _need a cost function_. Here, we can define a softmax loss function for the softmax prediction $\\hat{y}^{<t>}$ and the true word $y^{<t>}$. And the overall loss would be the sum of loss predicted for all timestamps.\n",
    "- At each step the model predicts the probability of the word at that step given the previous outputs\n",
    "\n",
    "## Character-level RNN\n",
    "\n",
    "- Depending on the application need we might build a character level or RNN, Where there vocabulary is alphabets (a-z), space, punctuation or even upper case letters if needed.\n",
    "- The output $\\hat{y}^{<t>}$ is the individual characters rather then individual words.\n",
    "- They can assign the unknown words with non-zero probability as they predict words but the disadvantage is we end up with much longer sequences. Hence, character-level models are not good as the word-level models in catching long range dependencies and computationally expensive to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ebf3f",
   "metadata": {},
   "source": [
    "## Character-wise RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa418d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sannin/miniconda3/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision                          # torch package for vision related things\n",
    "import torch.nn.functional as F             # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets     # Standard datasets\n",
    "import torchvision.transforms as transforms # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim                     # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn                        # All neural network modules\n",
    "from torch.utils.data import DataLoader     # Gives easier dataset management by creating mini batches etc.\n",
    "from tqdm import tqdm                       # For a nice progress bar!\n",
    "import matplotlib.pyplot as plt             # For Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99215d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Datasets/Character-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0081ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Datasets/Character-RNN/data.zip\n",
      "replace Datasets/Character-RNN/data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "# !wget https://download.pytorch.org/tutorial/data.zip -P Datasets/Character-RNN\n",
    "!unzip Datasets/Character-RNN/data.zip -d Datasets/Character-RNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ec6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic\n",
      "5000 5.0 2.1064 Yun / Korean CORRECT\n",
      "10000 10.0 1.9542 Jedlicka / Czech CORRECT\n",
      "15000 15.0 1.5433 Ly / Korean WRONG (Vietnamese)\n",
      "20000 20.0 2.0763 Rana / Spanish CORRECT\n",
      "25000 25.0 1.6493 Otten / Dutch CORRECT\n",
      "30000 30.0 1.2962 Tolbert / French CORRECT\n",
      "35000 35.0 0.1642 Komatsuzaki / Japanese CORRECT\n",
      "40000 40.0 2.1111 Lacey / Czech WRONG (English)\n",
      "45000 45.0 0.3270 Orsini / Italian CORRECT\n",
      "50000 50.0 2.3446 Stabile / French WRONG (Italian)\n",
      "55000 55.00000000000001 1.4544 Lambton / French WRONG (English)\n",
      "60000 60.0 1.9189 Abt / German CORRECT\n",
      "65000 65.0 1.2884 Desrochers / Greek WRONG (French)\n",
      "70000 70.0 2.4063 Mata / Japanese WRONG (Portuguese)\n",
      "75000 75.0 0.5201 Yuasa / Japanese CORRECT\n",
      "80000 80.0 1.7281 Maurice / French WRONG (Irish)\n",
      "85000 85.0 0.7614 Bao / Chinese CORRECT\n",
      "90000 90.0 1.7565 Ariwara / Czech WRONG (Japanese)\n",
      "95000 95.0 3.9259 Gravari / Italian WRONG (Greek)\n",
      "100000 100.0 0.0538 Gwozdek / Polish CORRECT\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import ALL_LETTERS, N_LETTERS\n",
    "from utils import load_data, letter_to_tensor, line_to_tensor, random_training_example\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    # implement RNN from scratch rather than using nn.RNN\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        combined = torch.cat((input_tensor, hidden_tensor), 1)\n",
    "        \n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "category_lines, all_categories = load_data()\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(N_LETTERS, n_hidden, n_categories)\n",
    "\n",
    "# one step\n",
    "input_tensor = letter_to_tensor('A')\n",
    "hidden_tensor = rnn.init_hidden()\n",
    "\n",
    "output, next_hidden = rnn(input_tensor, hidden_tensor)\n",
    "#print(output.size())\n",
    "#print(next_hidden.size())\n",
    "\n",
    "# whole sequence/name\n",
    "input_tensor = line_to_tensor('Albert')\n",
    "hidden_tensor = rnn.init_hidden()\n",
    "\n",
    "output, next_hidden = rnn(input_tensor[0], hidden_tensor)\n",
    "#print(output.size())\n",
    "#print(next_hidden.size())\n",
    "\n",
    "def category_from_output(output):\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]\n",
    "\n",
    "print(category_from_output(output))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(line_tensor, category_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "plot_steps, print_steps = 1000, 5000\n",
    "n_iters = 100000\n",
    "for i in range(n_iters):\n",
    "    category, line, category_tensor, line_tensor = random_training_example(category_lines, all_categories)\n",
    "    \n",
    "    output, loss = train(line_tensor, category_tensor)\n",
    "    current_loss += loss \n",
    "    \n",
    "    if (i+1) % plot_steps == 0:\n",
    "        all_losses.append(current_loss / plot_steps)\n",
    "        current_loss = 0\n",
    "        \n",
    "    if (i+1) % print_steps == 0:\n",
    "        guess = category_from_output(output)\n",
    "        correct = \"CORRECT\" if guess == category else f\"WRONG ({category})\"\n",
    "        print(f\"{i+1} {(i+1)/n_iters*100} {loss:.4f} {line} / {guess} {correct}\")\n",
    "        \n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "def predict(input_line):\n",
    "    print(f\"\\n> {input_line}\")\n",
    "    with torch.no_grad():\n",
    "        line_tensor = line_to_tensor(input_line)\n",
    "        \n",
    "        hidden = rnn.init_hidden()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "        guess = category_from_output(output)\n",
    "        print(guess)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31716417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> pho\n",
      "Portuguese\n",
      "\n",
      "> chan\n",
      "Irish\n",
      "\n",
      "> robert\n",
      "French\n",
      "\n",
      "> mary\n",
      "Scottish\n",
      "\n",
      "> ing\n",
      "Chinese\n",
      "\n",
      "> jing\n",
      "Chinese\n",
      "\n",
      "> Abalakoff\n",
      "Russian\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sentence = input(\"Input:\")\n",
    "    if sentence.strip() == \"quit\" or sentence.strip() == \"\":\n",
    "        break\n",
    "    \n",
    "    predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0a8fd",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2f46e",
   "metadata": {},
   "source": [
    "\n",
    "## Vanishing Gradients\n",
    "\n",
    "- One of the basic problems in RNN is it runs into vanishing gradients.\n",
    "- Language can have longer dependencies, the earliest word can affect a word that comes later.\n",
    "- For very deep neural networks, the gradient from output $\\hat{y}$ can have very hard time propagating backwards to affect the weights of earlier layers. In RNN we have same problem.\n",
    "- Exploding gradients can happen but it is easy to spot because the parameters value can blow causing `Nan` values. And, gradient clipping can be applied.\n",
    "\n",
    "## Model\n",
    "\n",
    "- LSTM model is similar to RNN but includes the concept of Gate and cell memory.\n",
    "\n",
    "![](https://www.researchgate.net/profile/Ayan-Chatterjee-11/publication/341735802/figure/fig4/AS:896548204462080@1590765157069/a-A-vanilla-LSTM-cell-b-Equations-of-a-vanilla-LSTM-cell.ppm)\n",
    "\n",
    "**RNN and LSTM comparison**\n",
    "\n",
    "![](https://i.stack.imgur.com/Iv3nU.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804211d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2a9db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.datasets import imdb\n",
    "import time\n",
    "import random\n",
    "# import pandas as pd\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.data.functional import simple_space_split\n",
    "from torchtext.data.functional import numericalize_tokens_from_iterator\n",
    "import numpy as np\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f7948",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496de647",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "VOCABULARY_SIZE = 10000\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e4add",
   "metadata": {},
   "source": [
    "### Dataset Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767765b5",
   "metadata": {},
   "source": [
    "#### Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186da835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\n",
    "# !gunzip -f movie_data.csv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d518be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('movie_data.csv')\n",
    "# print(df.head())\n",
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d92667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1aa628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Defining the feature processing\n",
    "\n",
    "# TEXT = torchtext.data.field(\n",
    "#     tokenize='spacy', # default splits on whitespace\n",
    "#     tokenizer_language='en_core_web_sm'\n",
    "# )\n",
    "\n",
    "# ### Defining the label processing\n",
    "\n",
    "# LABEL = torchtext.legacy.data.LabelField(dtype=torch.long)\n",
    "\n",
    "# fields = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\n",
    "\n",
    "# ### Process the dataset\n",
    "# dataset = torchtext.legacy.data.TabularDataset(\n",
    "#     path='movie_data.csv', format='csv',\n",
    "#     skip_header=True, fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed53eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81353134",
   "metadata": {},
   "source": [
    "#### Torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c50d86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Datasets/LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd31c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = imdb.IMDB(root=\"Datasets/LSTM/\", split=('train','test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d12300",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_tokens = []\n",
    "label_tokens = []\n",
    "def tokenize(line):\n",
    "    return line.split()\n",
    "for label, line in train_data:\n",
    "    line_tokens += tokenize(line)\n",
    "    label_tokens += tokenize(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2497fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'rented', 'I', 'AM', 'CURIOUS-YELLOW', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that']\n",
      "['neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(line_tokens[:15])\n",
    "print(label_tokens[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c180d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "unk_token = '<unk>'\n",
    "default_index = -1\n",
    "line_counter = Counter(line_tokens)\n",
    "# print(line_counter.most_common(10))\n",
    "line_sorted_by_freq_tuples = sorted(line_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(line_sorted_by_freq_tuples[:10])\n",
    "line_dict = OrderedDict(line_sorted_by_freq_tuples[:VOCABULARY_SIZE])\n",
    "line_vocab = vocab(line_dict, specials=[unk_token])\n",
    "line_vocab = line_vocab.to(DEVICE)\n",
    "line_vocab.set_default_index(default_index)\n",
    "print(line_vocab['<unk>']) #prints 0\n",
    "print(line_vocab['out of vocab']) #prints -1\n",
    "#make default index same as index of unk_token\n",
    "line_vocab.set_default_index(line_vocab[unk_token])\n",
    "line_vocab['out of vocab'] is line_vocab[unk_token] #prints True\n",
    "\n",
    "label_counter = Counter(label_tokens)\n",
    "sorted_by_freq_tuples = sorted(label_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "label_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "label_vocab = vocab(label_dict)\n",
    "label_vocab = label_vocab.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63459dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'I', 'that']\n",
      "38\n",
      "OrderedDict([('neg', 12500), ('pos', 12500)])\n",
      "['neg', 'pos']\n",
      "{'pos': 1, 'neg': 0}\n"
     ]
    }
   ],
   "source": [
    "# Lines Vocab\n",
    "print(line_vocab.get_itos()[:10])\n",
    "print(line_vocab.get_stoi()['has'])\n",
    "# Label Vocab\n",
    "print(label_dict)\n",
    "print(label_vocab.get_itos())\n",
    "print(label_vocab.get_stoi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "631f8581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object numericalize_tokens_from_iterator.<locals>.<genexpr> at 0x7f6ba9db4270>\n"
     ]
    }
   ],
   "source": [
    "for label,line in train_data:\n",
    "    line_ids_iter = numericalize_tokens_from_iterator(line_vocab, simple_space_split([line]))\n",
    "    print(next(line_ids_iter))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47b55ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\n",
      "[100]\n",
      "[789, 10001]\n",
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for i, (label,line) in enumerate(train_data):\n",
    "    line_ids_iter = numericalize_tokens_from_iterator(line_vocab, simple_space_split([line]))\n",
    "    tens = torch.from_numpy(np.fromiter(next(line_ids_iter), int))\n",
    "    print(list(tens.size()))\n",
    "    tens = torch.nn.functional.pad(tens,(1,500),\"constant\", 0)\n",
    "    print(list(tens[:100].size()))\n",
    "    one_h = torch.nn.functional.one_hot(tens, len(line_vocab))\n",
    "    print(list(one_h.size()))\n",
    "    print(one_h)\n",
    "    break  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df773e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_vocab.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b48c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "\n",
    "# nlp = spacy.blank(\"en\")\n",
    "# for i, (label, line) in enumerate(train_data):\n",
    "#     tokenized = [tok.text for tok in nlp.tokenizer(line)]\n",
    "#     indexed = [line_vocab.__getitem__(t) for t in tokenized]\n",
    "#     length = [len(indexed)]\n",
    "#     tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "#     tensor = tensor.unsqueeze(1)    \n",
    "#     length_tensor = torch.LongTensor(length)\n",
    "#     print(len(tokenized))\n",
    "#     print(len(indexed))\n",
    "#     print(list(tensor.size()))\n",
    "#     if i >3 :\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4df99a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imdb_Iter_dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, iter_dataset):\n",
    "        super(Imdb_Iter_dataset).__init__()\n",
    "        self.dataset = iter_dataset \n",
    "    def padding(batch):\n",
    "        doc = [doc['line'] for doc in batch]\n",
    "        len_doc = [len(doc['input']) for doc in batch]\n",
    "        doc_pad = pad_sequence(doc, batch_first=True, padding_value=0)\n",
    "        return doc_pad, len_doc\n",
    "    def __iter__(self):\n",
    "        for label,line in self.dataset:\n",
    "            label_ids_iter = numericalize_tokens_from_iterator(label_vocab, simple_space_split([label]))\n",
    "            line_ids_iter = numericalize_tokens_from_iterator(line_vocab, simple_space_split([line]))\n",
    "            label_tensor = torch.from_numpy(np.fromiter(next(label_ids_iter), int))\n",
    "            line_tensor = torch.from_numpy(np.fromiter(next(line_ids_iter), int))\n",
    "            one_h = torch.nn.functional.one_hot(line_tensor[:30], len(line_vocab))\n",
    "            # torch.nn.functional.pad(input=[500, 10001]) .to(device=DEVICE)\n",
    "            yield {\"label\":label_tensor, \"line\":one_h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7569acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_data = Imdb_Iter_dataset(train_data)\n",
    "test_iter_data = Imdb_Iter_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22902c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10001])\n",
      "torch.Size([30, 10001])\n",
      "torch.Size([30, 10001])\n",
      "torch.Size([30, 10001])\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(train_iter_data):\n",
    "    print(j['line'].size())\n",
    "    # print(j.size())\n",
    "    # print(k.size())\n",
    "    if i > 2 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8db013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleCustomBatch:\n",
    "#     def __init__(self, data):\n",
    "#         print(len(data))\n",
    "#         transposed_data = list(zip(*data))\n",
    "#         self.inp = torch.stack(transposed_data[0], 0)\n",
    "#         self.tgt = torch.stack(transposed_data[1], 0)\n",
    "\n",
    "#     # custom memory pinning method on custom type\n",
    "#     def pin_memory(self):\n",
    "#         self.inp = self.inp.pin_memory()\n",
    "#         self.tgt = self.tgt.pin_memory()\n",
    "#         return self\n",
    "\n",
    "# def collate_wrapper(batch):\n",
    "#     return SimpleCustomBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e9faa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_iter_data, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_iter_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34191b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,batch in enumerate(train_loader):\n",
    "#     print(i)\n",
    "#     print(type(batch[\"line\"]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0c3b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train')\n",
    "# for batch in train_loader:\n",
    "#     print(f'Text matrix size: {len(batch[1])}')\n",
    "#     print(f'Text matrix type: {type(batch[1])}')\n",
    "#     print(f'Text matrix size: {batch[1]}')\n",
    "\n",
    "#     print(f'Target vector size: {len(batch[0])}')\n",
    "#     print(f'Target vector type: {type(batch[0])}')\n",
    "#     print(f'Target vector size: {batch[0]}')\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77381469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim)        \n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "        # text dim: [sentence length, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # embedded dim: [sentence length, batch size, embedding dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # output dim: [sentence length, batch size, hidden dim]\n",
    "        # hidden dim: [1, batch size, hidden dim]\n",
    "\n",
    "        hidden.squeeze_(0)\n",
    "        # hidden dim: [batch size, hidden dim]\n",
    "        \n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d70caeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = LSTM(input_dim=len(line_vocab),\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=NUM_CLASSES # could use 1 for binary classification\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02257329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77781dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text = batch_data[\"line\"].to(DEVICE)\n",
    "        labels = batch_data[\"label\"].to(DEVICE)\n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%')\n",
    "        \n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24287623",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc0740",
   "metadata": {},
   "source": [
    "* https://www.coursera.org/learn/nlp-sequence-models\n",
    "* https://github.com/cedricdeboom/character-level-rnn-datasets\n",
    "* https://github.com/MycroftAI/rnn-demo\n",
    "* https://github.com/python-engineer/pytorch-examples/tree/master/rnn-name-classification\n",
    "* https://github.com/rasbt/stat453-deep-learning-ss21/blob/main/L15/1_lstm.ipynb\n",
    "* https://github.com/aladdinpersson/Machine-Learning-Collection\n",
    "* https://towardsdatascience.com/rnn-recurrent-neural-networks-how-to-successfully-model-sequential-data-in-python-5a0b9e494f92\n",
    "* https://www.simplilearn.com/tutorials/deep-learning-tutorial/rnn\n",
    "* https://github.com/python-engineer/pytorch-examples/tree/master/rnn-lstm-gru"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "009a5acded6e0d5bd336786bff52d2230829262ddf526a355327b86dcfc2d0a2"
  },
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
